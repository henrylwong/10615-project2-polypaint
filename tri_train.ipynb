{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _generate_equilateral_vertices(h, w, scale):\n",
    "  center_x, center_y = w / 2, h / 2\n",
    "  side_length = min(h, w) * 0.8 * scale\n",
    "  radius = side_length * math.sqrt(3) / 3\n",
    "\n",
    "  # Calculate the coordinates of the vertices using trigonometry\n",
    "  vertex1_x = center_x\n",
    "  vertex1_y = center_y - radius\n",
    "\n",
    "  vertex2_x = center_x + side_length / 2\n",
    "  vertex2_y = center_y + (radius / 2)\n",
    "\n",
    "  vertex3_x = center_x - side_length / 2\n",
    "  vertex3_y = center_y + (radius / 2)\n",
    "\n",
    "  return torch.tensor((vertex1_x, vertex1_y)), torch.tensor((vertex2_x, vertex2_y)), torch.tensor((vertex3_x, vertex3_y))\n",
    "\n",
    "def _point_in_triangle(x, y, v1, v2, v3):\n",
    "  # Compute barycentric coordinates to determine if point (x, y) is inside the triangle\n",
    "  b0 = ((v2[1] - v3[1]) * (x - v3[0]) + (v3[0] - v2[0]) * (y - v3[1])) / \\\n",
    "        ((v2[1] - v3[1]) * (v1[0] - v3[0]) + (v3[0] - v2[0]) * (v1[1] - v3[1]))\n",
    "  b1 = ((v3[1] - v1[1]) * (x - v3[0]) + (v1[0] - v3[0]) * (y - v3[1])) / \\\n",
    "        ((v2[1] - v3[1]) * (v1[0] - v3[0]) + (v3[0] - v2[0]) * (v1[1] - v3[1]))\n",
    "  b2 = 1 - b0 - b1\n",
    "  \n",
    "  return 0 <= b0 <= 1 and 0 <= b1 <= 1 and 0 <= b2 <= 1 \n",
    "\n",
    "def _fill_triangle(canvas, v1, v2, v3):\n",
    "  min_x = int(min(v1[0], v2[0], v3[0]))\n",
    "  max_x = int(max(v1[0], v2[0], v3[0]))\n",
    "  min_y = int(min(v1[1], v2[1], v3[1]))\n",
    "  max_y = int(max(v1[1], v2[1], v3[1]))\n",
    "  # Iterate over each pixel in the bounding box\n",
    "  for x in range(min_x, max_x + 1):\n",
    "    for y in range(min_y, max_y + 1):\n",
    "      # Check if the current pixel is inside the triangle\n",
    "      if _point_in_triangle(x, y, v1, v2, v3):\n",
    "        canvas[int(y), int(x)] = 1  # Set pixel to 1 (white)\n",
    "  return canvas\n",
    "\n",
    "def generate_equilateral_triangle(h, w, scale):\n",
    "  canvas = torch.zeros(h, w) \n",
    "  v1, v2, v3 = _generate_equilateral_vertices(h, w, scale)\n",
    "  canvas = _fill_triangle(canvas, v1, v2, v3)\n",
    "  return canvas\n",
    "\n",
    "def visualize_canvas(canvas):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(canvas.squeeze().numpy(), cmap='gray')\n",
    "    plt.title('Canvas with Triangles')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "h, w = 64, 128\n",
    "scale = 0.5\n",
    "\n",
    "canvas = generate_equilateral_triangle(h, w, scale)\n",
    "visualize_canvas(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CanvasDataset(Dataset):\n",
    "  def __init__(self, h, w, scales):\n",
    "    self.h = h\n",
    "    self.w = w\n",
    "    self.scales = scales\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.scales)  # Assuming scales is a list of input scales\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    scale = self.scales[idx]\n",
    "    canvas = generate_equilateral_triangle(self.h, self.w, scale)\n",
    "    return scale, canvas\n",
    "\n",
    "# Define the scales for the dataset\n",
    "scales = np.arange(0.05, 1.01, 0.01, dtype=np.float32)\n",
    "\n",
    "# Create an instance of the dataset\n",
    "dataset = CanvasDataset(h=64, w=128, scales=scales)\n",
    "\n",
    "# Create a dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrokeParametersToImage(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StrokeParametersToImage, self).__init__()\n",
    "        self.nh = 20\n",
    "        self.nc = 20\n",
    "        self.size_x = 128\n",
    "        self.size_y = 64\n",
    "        self.main = nn.Sequential(\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Linear(1, self.nh),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.BatchNorm1d(self.nh),\n",
    "            nn.Linear(self.nh, self.size_x*self.size_y),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Conv2d(1, self.nc, kernel_size=5, padding='same', dilation=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.BatchNorm2d(self.nc),\n",
    "            nn.Conv2d(self.nc, 1, kernel_size=5, padding='same', dilation=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        x = x.view(-1, 1, self.size_y, self.size_x)\n",
    "        x = self.conv(x)[:,0]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch [1/6], Loss: 0.2703823447227478\n",
      "Epoch [1/10], Batch [2/6], Loss: 0.26819634437561035\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     12\u001b[0m     batch_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m scales, triangles \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     14\u001b[0m         scales, triangles \u001b[38;5;241m=\u001b[39m scales\u001b[38;5;241m.\u001b[39mto(device), triangles\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m, in \u001b[0;36mCanvasDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     11\u001b[0m   scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscales[idx]\n\u001b[0;32m---> 12\u001b[0m   canvas \u001b[38;5;241m=\u001b[39m generate_equilateral_triangle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw, scale)\n\u001b[1;32m     13\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m scale, canvas\n",
      "Cell \u001b[0;32mIn[3], line 44\u001b[0m, in \u001b[0;36mgenerate_equilateral_triangle\u001b[0;34m(h, w, scale)\u001b[0m\n\u001b[1;32m     42\u001b[0m canvas \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(h, w) \n\u001b[1;32m     43\u001b[0m v1, v2, v3 \u001b[38;5;241m=\u001b[39m _generate_equilateral_vertices(h, w, scale)\n\u001b[0;32m---> 44\u001b[0m canvas \u001b[38;5;241m=\u001b[39m _fill_triangle(canvas, v1, v2, v3)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m canvas\n",
      "Cell \u001b[0;32mIn[3], line 37\u001b[0m, in \u001b[0;36m_fill_triangle\u001b[0;34m(canvas, v1, v2, v3)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(min_x, max_x \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(min_y, max_y \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Check if the current pixel is inside the triangle\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _point_in_triangle(x, y, v1, v2, v3):\n\u001b[1;32m     38\u001b[0m       canvas[\u001b[38;5;28mint\u001b[39m(y), \u001b[38;5;28mint\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Set pixel to 1 (white)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m canvas\n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36m_point_in_triangle\u001b[0;34m(x, y, v1, v2, v3)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_point_in_triangle\u001b[39m(x, y, v1, v2, v3):\n\u001b[1;32m     19\u001b[0m   \u001b[38;5;66;03m# Compute barycentric coordinates to determine if point (x, y) is inside the triangle\u001b[39;00m\n\u001b[1;32m     20\u001b[0m   b0 \u001b[38;5;241m=\u001b[39m ((v2[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m v3[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m*\u001b[39m (x \u001b[38;5;241m-\u001b[39m v3[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m (v3[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m v2[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m (y \u001b[38;5;241m-\u001b[39m v3[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m/\u001b[39m \\\n\u001b[1;32m     21\u001b[0m         ((v2[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m v3[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m*\u001b[39m (v1[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m v3[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m (v3[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m v2[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m (v1[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m v3[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m---> 22\u001b[0m   b1 \u001b[38;5;241m=\u001b[39m ((v3[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m v1[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m*\u001b[39m (x \u001b[38;5;241m-\u001b[39m v3[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m (v1[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m v3[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m (y \u001b[38;5;241m-\u001b[39m v3[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m/\u001b[39m \\\n\u001b[1;32m     23\u001b[0m         ((v2[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m v3[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m*\u001b[39m (v1[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m v3[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m (v3[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m v2[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m (v1[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m v3[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     24\u001b[0m   b2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m b0 \u001b[38;5;241m-\u001b[39m b1\n\u001b[1;32m     26\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m b0 \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m b1 \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m b2 \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:34\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m(f):\n\u001b[1;32m     32\u001b[0m     assigned \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mWRAPPER_ASSIGNMENTS\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f, assigned\u001b[38;5;241m=\u001b[39massigned)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = StrokeParametersToImage()\n",
    "torch.compile(model)\n",
    "model.to(device)\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 1000\n",
    "\n",
    "# Iterate over your dataset for training\n",
    "for epoch in range(num_epochs):\n",
    "    batch_idx = 0\n",
    "    for scales, triangles in dataloader:\n",
    "        scales, triangles = scales.to(device), triangles.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(scales.unsqueeze(1))\n",
    "        # print(output.shape, triangles.shape)\n",
    "        loss = criterion(output, triangles)  # Define your target here\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print metrics\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(dataloader)}], Loss: {loss.item()}')\n",
    "        batch_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "scale = torch.tensor([0.6], requires_grad=True).unsqueeze(0)\n",
    "# print(scale.shape)\n",
    "canvas = model.forward(scale)\n",
    "print(canvas.grad_fn)\n",
    "visualize_canvas(canvas.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CanvasDataset(Dataset):\n",
    "  def __init__(self, h, w, scales):\n",
    "    self.h = h\n",
    "    self.w = w\n",
    "    self.scales = scales\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.scales)  # Assuming scales is a list of input scales\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    scale = self.scales[idx]\n",
    "    canvas = generate_equilateral_triangle(self.h, self.w, scale)\n",
    "    return scale, canvas\n",
    "\n",
    "# Define the scales for the dataset\n",
    "scales = np.arange(0.05, 1.01, 0.01, dtype=np.float32)\n",
    "\n",
    "# Create an instance of the dataset\n",
    "dataset = CanvasDataset(h=64, w=128, scales=scales)\n",
    "\n",
    "# Create a dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (537791267.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[74], line 14\u001b[0;36m\u001b[0m\n\u001b[0;31m    scales, triangles = scaledeviceEVICE), triangledeviceEVICE)\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "model = StrokeParametersToImage()\n",
    "torch.compile(model)\n",
    "model.to(DeviceEVICE)\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "\n",
    "# Iterate over your dataset for training\n",
    "for epoch in range(num_epochs):\n",
    "    batch_idx = 0\n",
    "    for scales, triangles in dataloader:\n",
    "        scales, triangles = scale.to(DEVICE), triangles.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(scales.unsqueeze(1))\n",
    "        # print(output.shape, triangles.shape)\n",
    "        loss = criterion(output, triangles)  # Define your target here\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print metrics\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(dataloader)}], Loss: {loss.item()}')\n",
    "        batch_idx += 1d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
